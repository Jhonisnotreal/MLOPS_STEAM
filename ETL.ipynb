{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries, defining paths & creating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries and paths\n",
    "\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import ast\n",
    "\n",
    "# Paths\n",
    "\n",
    "path1 = 'Datasets/steam_games.json.gz'\n",
    "path2 = 'Datasets/user_reviews.json.gz'\n",
    "path3 = 'Datasets/users_items.json.gz'\n",
    "\n",
    "# Creating a function to read the paths\n",
    "\n",
    "def read_path(file):\n",
    "    with gzip.open(file, 'rt', encoding='utf-8') as myfile:\n",
    "        return [ast.literal_eval(line.strip()) for line in myfile]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Let's read all the datasets\n",
    "\n",
    "# Reading the dataset from 'steam_games.json.gz' ↓↓↓\n",
    "with gzip.open(path1, 'rt', encoding='utf-8') as file:\n",
    "    df_games = pd.read_json(file, lines=True)\n",
    "\n",
    "# Reading datasets \n",
    "reviews = read_path(path2)\n",
    "items = read_path(path3)\n",
    "\n",
    "# Transforming datasets to dataframes ↓:\n",
    "df_reviews = pd.DataFrame(reviews)\n",
    "df_items = pd.DataFrame(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL\n",
    "\n",
    "We are going to extract, transform and load data from datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's begin cleaning 'df_games'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with df_games\n",
    "\n",
    "# In the next code cell, I'm going to delete specific columns that we don't need for the tasks\n",
    "\n",
    "df_games.drop(['publisher','url','reviews_url','price','early_access','developer','specs'],axis=1,inplace=True)\n",
    "\n",
    "# I use inplace=True because I want to change the original dataframe too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, We drop rows where are only null values\n",
    "\n",
    "df_games.dropna(axis=0, how='all', inplace=True)\n",
    "\n",
    "# Also, we drop dulicates in 'id' column\n",
    "\n",
    "df_games.drop_duplicates(subset=['id'], inplace=True)\n",
    "\n",
    "# Now, let's drop values where there is no genres, tags, app_name and title, this is because it will only cause latency in the EDA process\n",
    "\n",
    "df_games.dropna(subset=['genres','tags'],how='all', inplace=True)\n",
    "df_games.dropna(subset=['app_name','title'],how='all', inplace=True)\n",
    "\n",
    "# We change the type of value in 'id' column to integer\n",
    "df_games['id'].fillna(0, inplace=True)\n",
    "df_games['id'] = df_games['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's time to transform 'release_date' column. If it's a null value just returns 'None'\n",
    "# But if it's a value, just transform to datetime type \n",
    "\n",
    "def datetime_change(var):\n",
    "\n",
    "    if pd.isna(var):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        return pd.to_datetime(var)\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games[\"release_date\"] = df_games[\"release_date\"].apply(datetime_change)\n",
    "\n",
    "df_games[\"release_year\"] = df_games[\"release_date\"].dt.year\n",
    "\n",
    "df_games['release_date'] = df_games['release_date'].astype('int64').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last but not least let's save it to a csv file\n",
    "\n",
    "df_games = df_games.to_csv('Games.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Step: Let's clean 'df_reviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnesting(dataframe,column):\n",
    "    \n",
    "    df_aux = dataframe.explode(column)\n",
    "    df_normal = pd.json_normalize(df_aux[column].dropna())\n",
    "\n",
    "    df_aux.reset_index(inplace=True)\n",
    "    df_normal.reset_index(inplace=True)\n",
    "    dataframe = pd.concat([df_aux,df_normal],axis=1)\n",
    "    dataframe.dropna(inplace=True)\n",
    "    \n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = unnesting(df_reviews, \"reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'user_id', 'user_url', 'reviews', 'index', 'funny', 'posted',\n",
       "       'last_edited', 'item_id', 'helpful', 'recommend', 'review'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the date\n",
    "\n",
    "df_reviews[\"posted\"] = df_reviews[\"posted\"].str.extract(r\"Posted ([\\w\\s\\d,]+)\") \n",
    "df_reviews[\"posted_date\"] = df_reviews[\"posted\"].apply(datetime_change) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index          59277\n",
       "user_id        59277\n",
       "user_url       59277\n",
       "reviews        59277\n",
       "index          59277\n",
       "funny          59277\n",
       "posted             0\n",
       "last_edited    59277\n",
       "item_id        59277\n",
       "helpful        59277\n",
       "recommend      59277\n",
       "review         59277\n",
       "posted_date        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_reviews['posted_date']\n",
    "\n",
    "mask = df_reviews['posted_date'] != None\n",
    "df_reviews[mask].count()\n",
    "#df_reviews[\"posted_date\"].dt.year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.drop([\"reviews\",\"last_edited\",\"index\",\"posted\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third step: Cleaning 'df_items'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save the file again\n",
    "\n",
    "df_items_data = df_items.to_parquet(\"df_items_data.parquet\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a sample because is too big \n",
    "\n",
    "df_items_sample = df_items.sample(10000)\n",
    "df_items_sample.to_parquet(\"df_items_sample.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did I choose Parquet? This is related to the structure of the dataset itself.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
